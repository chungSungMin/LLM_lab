{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3547875d",
   "metadata": {},
   "source": [
    "# PDF와 JSONL 파일을 읽어서 같이 RAG로 할용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6c8f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re \n",
    "import json \n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3c48cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_paths = [\n",
    "    \"/workspace/거버넌스.pdf\",\n",
    "]\n",
    "\n",
    "# 예시에서는 jsonl은 question과 answer로 구성되어있습니다.\n",
    "jsonl_file_paths = [\n",
    "    \"/workspace/2025-AI-Challeng-finance/cybersecurity_data_regex_cleaned.jsonl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e650dc1",
   "metadata": {},
   "source": [
    "# PDF 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e458fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path:str) -> str : \n",
    "    try :\n",
    "        with fitz.open(pdf_path) as doc : \n",
    "            return \"\".join(page.get_text() for page in doc)\n",
    "    except Exception as e : \n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "def chunk_general_pdf(text:str, source:str) -> list[Document] : \n",
    "    if not text :\n",
    "        return []\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=126,\n",
    "        separators=[\"\\n\\n\", \"\\n\"]\n",
    "    ) \n",
    "\n",
    "    # text를 text_splitter를 통해서 잘게 분리합니다.\n",
    "    chuncks = text_splitter.split_text(text)\n",
    "\n",
    "    documents = []\n",
    "    # Document 형식으로 변환 해주어야지 vector DB 저장이 가능합니다.\n",
    "    # chunck들을 page_content에 넣고, 추가 metadata를 넣어줍니다.\n",
    "    for i, chunk in enumerate(chuncks) : \n",
    "        doc = Document(\n",
    "            page_content = chunk,\n",
    "            metadata = {\"source\":source, \"chunk_num\":i+1, \"data_type\":\"general_pdf\"}\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57891b",
   "metadata": {},
   "source": [
    "# JSONL 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8984eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunck_QA_jsonl(text:str, all_documents:list[Document]) -> list[Document] : \n",
    "    if not text : \n",
    "        return []\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1024,\n",
    "        chunk_overlap=126\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_text(text)\n",
    "    print(f\"{len(split_docs)}개의 'Q&A' 청크를 추가했습니다.\")\n",
    "\n",
    "    for doc in split_docs:\n",
    "        doc.metadata[\"data_type\"] = \"qna_jsonl\"\n",
    "    all_documents.extend(doc)\n",
    "\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae658d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======PDF 데이터를 처리합니다======\n",
      "/workspace/거버넌스.pdf처리중........\n",
      "/workspace/거버넌스.pdf파일 정리가 완료되었습니다 => 7개의 청크 생성완료.\n",
      "/workspace/2025-AI-Challeng-finance/cybersecurity_data_regex_cleaned.jsonl처리중........\n",
      "expected string or bytes-like object, got 'list'\n"
     ]
    }
   ],
   "source": [
    "all_documents = []\n",
    "\n",
    "print(f'=======PDF 데이터를 처리합니다======')\n",
    "\n",
    "for pdf_path in pdf_file_paths:\n",
    "    print(f\"{pdf_path}처리중........\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text : \n",
    "        print(f\"{pdf_path}에는 아무런 text가 존재하지 않아 건너뜁니다.🦘\")\n",
    "        continue\n",
    "\n",
    "    documents = chunk_general_pdf(text, pdf_path)\n",
    "    all_documents.extend(documents)\n",
    "    print(f\"{pdf_path}파일 정리가 완료되었습니다 => {len(documents)}개의 청크 생성완료.\")\n",
    "\n",
    "\n",
    "for jsonl_path in jsonl_file_paths:\n",
    "    print(f\"{jsonl_path}처리중........\")\n",
    "    try:\n",
    "        loader = JSONLoader(\n",
    "            file_path=jsonl_path,\n",
    "            # 예시 jsonl이 {\"question\" : , \"answer\" : } 형식이기 때문에 다음과 같이 사용\n",
    "            jq_schema='\"질문: \" + .question + \"\\\\n답변: \" + .answer',\n",
    "            json_lines=True\n",
    "        )\n",
    "        documents_from_jsonl = loader.load()\n",
    "        doc = chunck_QA_jsonl(documents_from_jsonl, all_documents)\n",
    "\n",
    "    except Exception as e : \n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d07dbddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ✅ 최종 통합 완료 ---\n",
      "모든 파일로부터 총 7개의 Document를 생성했습니다.\n",
      "\n",
      "📑 일반 PDF에서 온 데이터 샘플:\n",
      "page_content='거버넌스\n",
      "거버넌스(governance)는 일반적으로 ‘과거의 일방적인 정부 주도적 경향에서 벗어나 정부, 기업, 비정부\n",
      "기구 등 다양한 행위자가 공동의 관심사에 대한 네트워크를 구축하여 문제를 해결하는 새로운 국정운영\n",
      "의 방식’을 말한다.[1] 그렇지만 다양한 학문 분야에서 서로 다른 맥락으로 쓰이고 있어, 아직 정의에 대한\n",
      "명확한 학문적 합의는 이루어지지 않았다고 볼 수 있다.[2]\n",
      "거버넌스는 일반적으로, 그리고 학문적으로 빈번히 사용됨에도 불구하고, 그 다양한 의미로 인해 정의가\n",
      "쉽지 않다. 이는 다양한 학문 분야에서 서로 다른 맥락으로 사용되고 있기 때문이다.[3]\n",
      "존 피에르(Jon Pierre)와 피터스(B. Guy Peters)는 “정책 결정에 있어 정부 주도의 통제와 관리에서 벗어나\n",
      "다양한 이해당사자가 주체적인 행위자로 협의와 합의 과정을 통하여 정책을 결정하고 집행해 나가는 사\n",
      "회적 통치 시스템”으로 정의했다.[4]' metadata={'source': '/workspace/거버넌스.pdf', 'chunk_num': 1, 'data_type': 'general_pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- ✅ 최종 통합 완료 ---\")\n",
    "print(f\"모든 파일로부터 총 {len(all_documents)}개의 Document를 생성했습니다.\")\n",
    "\n",
    "if all_documents:\n",
    "    general_pdf_sample = next((doc for doc in all_documents if doc.metadata.get(\"data_type\") == \"general_pdf\"), None)\n",
    "    if general_pdf_sample:\n",
    "        print(\"\\n📑 일반 PDF에서 온 데이터 샘플:\")\n",
    "        print(general_pdf_sample)\n",
    "    \n",
    "    jsonl_sample = next((doc for doc in all_documents if doc.metadata.get(\"data_type\") == \"qna_jsonl\"), None)\n",
    "    if jsonl_sample:\n",
    "        print(\"\\n📝 JSONL에서 온 데이터 샘플:\")\n",
    "        print(jsonl_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db2d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a276aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

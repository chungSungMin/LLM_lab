{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3547875d",
   "metadata": {},
   "source": [
    "# PDFì™€ JSONL íŒŒì¼ì„ ì½ì–´ì„œ ê°™ì´ RAGë¡œ í• ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6c8f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re \n",
    "import json \n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3c48cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_paths = [\n",
    "    \"/workspace/á„€á…¥á„‡á…¥á„‚á…¥á†«á„‰á…³.pdf\",\n",
    "]\n",
    "\n",
    "# ì˜ˆì‹œì—ì„œëŠ” jsonlì€ questionê³¼ answerë¡œ êµ¬ì„±ë˜ì–´ìˆìŠµë‹ˆë‹¤.\n",
    "jsonl_file_paths = [\n",
    "    \"/workspace/2025-AI-Challeng-finance/cybersecurity_data_regex_cleaned.jsonl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e650dc1",
   "metadata": {},
   "source": [
    "# PDF ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e458fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path:str) -> str : \n",
    "    try :\n",
    "        with fitz.open(pdf_path) as doc : \n",
    "            return \"\".join(page.get_text() for page in doc)\n",
    "    except Exception as e : \n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "def chunk_general_pdf(text:str, source:str) -> list[Document] : \n",
    "    if not text :\n",
    "        return []\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=126,\n",
    "        separators=[\"\\n\\n\", \"\\n\"]\n",
    "    ) \n",
    "\n",
    "    # textë¥¼ text_splitterë¥¼ í†µí•´ì„œ ì˜ê²Œ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "    chuncks = text_splitter.split_text(text)\n",
    "\n",
    "    documents = []\n",
    "    # Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜ í•´ì£¼ì–´ì•¼ì§€ vector DB ì €ì¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "    # chunckë“¤ì„ page_contentì— ë„£ê³ , ì¶”ê°€ metadataë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.\n",
    "    for i, chunk in enumerate(chuncks) : \n",
    "        doc = Document(\n",
    "            page_content = chunk,\n",
    "            metadata = {\"source\":source, \"chunk_num\":i+1, \"data_type\":\"general_pdf\"}\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57891b",
   "metadata": {},
   "source": [
    "# JSONL ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8984eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunck_QA_jsonl(text:str, all_documents:list[Document]) -> list[Document] : \n",
    "    if not text : \n",
    "        return []\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1024,\n",
    "        chunk_overlap=126\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_text(text)\n",
    "    print(f\"{len(split_docs)}ê°œì˜ 'Q&A' ì²­í¬ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    for doc in split_docs:\n",
    "        doc.metadata[\"data_type\"] = \"qna_jsonl\"\n",
    "    all_documents.extend(doc)\n",
    "\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae658d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======PDF ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤======\n",
      "/workspace/á„€á…¥á„‡á…¥á„‚á…¥á†«á„‰á…³.pdfì²˜ë¦¬ì¤‘........\n",
      "/workspace/á„€á…¥á„‡á…¥á„‚á…¥á†«á„‰á…³.pdfíŒŒì¼ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ => 7ê°œì˜ ì²­í¬ ìƒì„±ì™„ë£Œ.\n",
      "/workspace/2025-AI-Challeng-finance/cybersecurity_data_regex_cleaned.jsonlì²˜ë¦¬ì¤‘........\n",
      "expected string or bytes-like object, got 'list'\n"
     ]
    }
   ],
   "source": [
    "all_documents = []\n",
    "\n",
    "print(f'=======PDF ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤======')\n",
    "\n",
    "for pdf_path in pdf_file_paths:\n",
    "    print(f\"{pdf_path}ì²˜ë¦¬ì¤‘........\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text : \n",
    "        print(f\"{pdf_path}ì—ëŠ” ì•„ë¬´ëŸ° textê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ê±´ë„ˆëœë‹ˆë‹¤.ğŸ¦˜\")\n",
    "        continue\n",
    "\n",
    "    documents = chunk_general_pdf(text, pdf_path)\n",
    "    all_documents.extend(documents)\n",
    "    print(f\"{pdf_path}íŒŒì¼ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ => {len(documents)}ê°œì˜ ì²­í¬ ìƒì„±ì™„ë£Œ.\")\n",
    "\n",
    "\n",
    "for jsonl_path in jsonl_file_paths:\n",
    "    print(f\"{jsonl_path}ì²˜ë¦¬ì¤‘........\")\n",
    "    try:\n",
    "        loader = JSONLoader(\n",
    "            file_path=jsonl_path,\n",
    "            # ì˜ˆì‹œ jsonlì´ {\"question\" : , \"answer\" : } í˜•ì‹ì´ê¸° ë•Œë¬¸ì— ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©\n",
    "            jq_schema='\"ì§ˆë¬¸: \" + .question + \"\\\\në‹µë³€: \" + .answer',\n",
    "            json_lines=True\n",
    "        )\n",
    "        documents_from_jsonl = loader.load()\n",
    "        doc = chunck_QA_jsonl(documents_from_jsonl, all_documents)\n",
    "\n",
    "    except Exception as e : \n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d07dbddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- âœ… ìµœì¢… í†µí•© ì™„ë£Œ ---\n",
      "ëª¨ë“  íŒŒì¼ë¡œë¶€í„° ì´ 7ê°œì˜ Documentë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“‘ ì¼ë°˜ PDFì—ì„œ ì˜¨ ë°ì´í„° ìƒ˜í”Œ:\n",
      "page_content='ê±°ë²„ë„ŒìŠ¤\n",
      "ê±°ë²„ë„ŒìŠ¤(governance)ëŠ” ì¼ë°˜ì ìœ¼ë¡œ â€˜ê³¼ê±°ì˜ ì¼ë°©ì ì¸ ì •ë¶€ ì£¼ë„ì  ê²½í–¥ì—ì„œ ë²—ì–´ë‚˜ ì •ë¶€, ê¸°ì—…, ë¹„ì •ë¶€\n",
      "ê¸°êµ¬ ë“± ë‹¤ì–‘í•œ í–‰ìœ„ìê°€ ê³µë™ì˜ ê´€ì‹¬ì‚¬ì— ëŒ€í•œ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì¶•í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ êµ­ì •ìš´ì˜\n",
      "ì˜ ë°©ì‹â€™ì„ ë§í•œë‹¤.[1] ê·¸ë ‡ì§€ë§Œ ë‹¤ì–‘í•œ í•™ë¬¸ ë¶„ì•¼ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë§¥ë½ìœ¼ë¡œ ì“°ì´ê³  ìˆì–´, ì•„ì§ ì •ì˜ì— ëŒ€í•œ\n",
      "ëª…í™•í•œ í•™ë¬¸ì  í•©ì˜ëŠ” ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.[2]\n",
      "ê±°ë²„ë„ŒìŠ¤ëŠ” ì¼ë°˜ì ìœ¼ë¡œ, ê·¸ë¦¬ê³  í•™ë¬¸ì ìœ¼ë¡œ ë¹ˆë²ˆíˆ ì‚¬ìš©ë¨ì—ë„ ë¶ˆêµ¬í•˜ê³ , ê·¸ ë‹¤ì–‘í•œ ì˜ë¯¸ë¡œ ì¸í•´ ì •ì˜ê°€\n",
      "ì‰½ì§€ ì•Šë‹¤. ì´ëŠ” ë‹¤ì–‘í•œ í•™ë¬¸ ë¶„ì•¼ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë§¥ë½ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆê¸° ë•Œë¬¸ì´ë‹¤.[3]\n",
      "ì¡´ í”¼ì—ë¥´(Jon Pierre)ì™€ í”¼í„°ìŠ¤(B. Guy Peters)ëŠ” â€œì •ì±… ê²°ì •ì— ìˆì–´ ì •ë¶€ ì£¼ë„ì˜ í†µì œì™€ ê´€ë¦¬ì—ì„œ ë²—ì–´ë‚˜\n",
      "ë‹¤ì–‘í•œ ì´í•´ë‹¹ì‚¬ìê°€ ì£¼ì²´ì ì¸ í–‰ìœ„ìë¡œ í˜‘ì˜ì™€ í•©ì˜ ê³¼ì •ì„ í†µí•˜ì—¬ ì •ì±…ì„ ê²°ì •í•˜ê³  ì§‘í–‰í•´ ë‚˜ê°€ëŠ” ì‚¬\n",
      "íšŒì  í†µì¹˜ ì‹œìŠ¤í…œâ€ìœ¼ë¡œ ì •ì˜í–ˆë‹¤.[4]' metadata={'source': '/workspace/á„€á…¥á„‡á…¥á„‚á…¥á†«á„‰á…³.pdf', 'chunk_num': 1, 'data_type': 'general_pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- âœ… ìµœì¢… í†µí•© ì™„ë£Œ ---\")\n",
    "print(f\"ëª¨ë“  íŒŒì¼ë¡œë¶€í„° ì´ {len(all_documents)}ê°œì˜ Documentë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "if all_documents:\n",
    "    general_pdf_sample = next((doc for doc in all_documents if doc.metadata.get(\"data_type\") == \"general_pdf\"), None)\n",
    "    if general_pdf_sample:\n",
    "        print(\"\\nğŸ“‘ ì¼ë°˜ PDFì—ì„œ ì˜¨ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "        print(general_pdf_sample)\n",
    "    \n",
    "    jsonl_sample = next((doc for doc in all_documents if doc.metadata.get(\"data_type\") == \"qna_jsonl\"), None)\n",
    "    if jsonl_sample:\n",
    "        print(\"\\nğŸ“ JSONLì—ì„œ ì˜¨ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "        print(jsonl_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db2d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a276aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
